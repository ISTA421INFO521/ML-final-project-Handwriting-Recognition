{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!sudo apt update && sudo apt install espeak ffmpeg libespeak1\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "6LcLg_lifJt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PUzvzocuPrj",
        "outputId": "7c0ae0c0-4f53-4179-9bf1-d1817a7deb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cd9G-qDmueHV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!cp -r /content/drive/MyDrive/521\\ ML\\ \\ final\\ project/dataset/iam/compressed /\n",
        "!rm -r /words\n",
        "!mkdir -p /words\n",
        "!tar xvzf /compressed/words.tgz -C /words\n",
        "!rm -r /lines\n",
        "!mkdir -p /lines\n",
        "!tar xvzf /compressed/lines.tgz -C /lines\n",
        "!rm -r /forms\n",
        "!mkdir -p /forms\n",
        "!tar xvzf /compressed/formsA-D.tgz -C /forms\n",
        "!tar xvzf /compressed/formsE-H.tgz -C /forms\n",
        "!tar xvzf /compressed/formsI-Z.tgz -C /forms\n",
        "!rm -r /words_label\n",
        "!mkdir -p /words_label\n",
        "!tar xvzf /compressed/ascii.tgz -C /words_label\n",
        "!rm -r /xml\n",
        "!mkdir -p /xml\n",
        "!tar xvzf /compressed/xml.tgz -C /xml\n",
        "!rm -r /samples\n",
        "!mkdir -p /samples\n",
        "!cp -r /content/drive/MyDrive/521\\ ML\\ \\ final\\ project/dataset/iam/samples/* /samples/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "from skimage.filters import sobel \n",
        "from numpy.lib.type_check import imag\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,KFold,cross_validate\n",
        "from sklearn.metrics import recall_score,f1_score,precision_score,accuracy_score,confusion_matrix\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn import preprocessing\n",
        "import string\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n"
      ],
      "metadata": {
        "id": "CVdsOcFe1wAs"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2022)\n"
      ],
      "metadata": {
        "id": "as6RpD7e1yQY"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word(line):\n",
        "  return \" \".join(line.split(\"\\n\")[0].split(\" \")[8:]).strip()"
      ],
      "metadata": {
        "id": "CiUMZY_xYFWn"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_words_and_counter(file_path):\n",
        "  unique_words = defaultdict(list)\n",
        "  counter_input_data = []\n",
        "  word_file = open(file_path, \"r\").readlines()\n",
        "  for line in word_file:\n",
        "      if line[0] == \"#\":\n",
        "          continue\n",
        "      if line.split(\" \")[1] != \"err\":\n",
        "          word = get_word(line)\n",
        "          unique_words[word].append(line.strip())\n",
        "          counter_input_data.append(word)\n",
        "  return unique_words,counter_input_data\n"
      ],
      "metadata": {
        "id": "lPhXIXYuZdFP"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "oHmaTEH9yHps"
      },
      "outputs": [],
      "source": [
        "def filter_labels(most_common_words,unique_words,max_words,max_images_per_word): \n",
        "  filtered_labels = []\n",
        "  num_word = 0\n",
        "  for word,size in most_common_words:\n",
        "    flag = False\n",
        "    for char in word:\n",
        "      if char in string.ascii_letters:\n",
        "        flag=True\n",
        "        break\n",
        "    if flag:\n",
        "      if num_word < max_words:\n",
        "        if size >= max_images_per_word:\n",
        "            filtered_labels.extend(unique_words[word][0:max_images_per_word])\n",
        "            num_word+=1\n",
        "      else:\n",
        "        break        \n",
        "  return filtered_labels\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels_for_the_words(unique_words,words,max_images_per_word):\n",
        "  labels = []\n",
        "  for word in unique_words:\n",
        "    if word in words:\n",
        "      labels.extend(unique_words[word][0:max_images_per_word])\n",
        "  return labels"
      ],
      "metadata": {
        "id": "1H_ewl8XShhe"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_for_labels_based_on_training_words(file_path,train_words,max_images_per_word):\n",
        "  unique_words,counter_input_data = get_unique_words_and_counter(file_path)\n",
        "  input_for_labels = get_labels_for_the_words(unique_words,train_words,max_images_per_word)\n",
        "  return input_for_labels"
      ],
      "metadata": {
        "id": "GI2xP658ZYFy"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_for_labels_based_max_size(file_path,max_words=50,max_images_per_word=100):\n",
        "  unique_words,counter_input_data = get_unique_words_and_counter(file_path)\n",
        "  counter_data=Counter(counter_input_data)    \n",
        "  most_common_words = counter_data.most_common()\n",
        "  input_for_labels = filter_labels(most_common_words,unique_words,max_words,max_images_per_word)\n",
        "  return input_for_labels"
      ],
      "metadata": {
        "id": "O2TKN2yd4txk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(image_path,color=False):\n",
        "    if color:\n",
        "      img = cv2.imread(image_path)\n",
        "      img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "      h, w, c = img.shape\n",
        "\n",
        "      if w > 1000:\n",
        "          \n",
        "          new_w = 1000\n",
        "          ar = w/h\n",
        "          new_h = int(new_w/ar)\n",
        "          \n",
        "          img = cv2.resize(img, (new_w, new_h), interpolation = cv2.INTER_AREA)\n",
        "    else:\n",
        "        img = cv2.imread(image_path,cv2.IMREAD_GRAYSCALE)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "Fn1gAnl5BEOz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(img):\n",
        "    resized_img = cv2.resize(img,IMAGE_SIZE)\n",
        "    image_array = np.array(resized_img).flatten()\n",
        "    return image_array"
      ],
      "metadata": {
        "id": "ZT9jPptuATjL"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(image):\n",
        "  plt.imshow(image, cmap='gray')"
      ],
      "metadata": {
        "id": "r4Cx0xeKFRCH"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "T7pkcOUgykNp"
      },
      "outputs": [],
      "source": [
        "def get_images_and_labels(base_path, samples,IMAGE_SIZE):\n",
        "    base_image_path = os.path.join(base_path, \"/words\")\n",
        "    data = []\n",
        "    for (i, file_line) in enumerate(samples):\n",
        "        line_split = file_line.strip()\n",
        "        line_split = line_split.split(\" \")\n",
        "        image_name = line_split[0]\n",
        "        partI = image_name.split(\"-\")[0]\n",
        "        partII = image_name.split(\"-\")[1]\n",
        "        img_path = os.path.join(\n",
        "            base_image_path, partI, partI + \"-\" + partII, image_name + \".png\"\n",
        "        )\n",
        "        if os.path.getsize(img_path):\n",
        "            img = read_image(img_path)\n",
        "            image_array = process_image(img)\n",
        "            label = get_word(file_line)\n",
        "            data.append((image_array,label))\n",
        "    return data\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "1r42cApS2hIC"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_features_and_labels(input_data, label_encoder):\n",
        "  tmp_features = []\n",
        "  tmp_labels =[]\n",
        "  for feature,label in input_data:\n",
        "      tmp_features.append(feature)\n",
        "      tmp_labels.append(label)\n",
        "  features = np.array(tmp_features)\n",
        "  labels =label_encoder.fit_transform(np.array(tmp_labels))\n",
        "  return features,labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "dWP9Mq2hMJRc"
      },
      "outputs": [],
      "source": [
        "def get_gaussian_model(model_name):\n",
        "  models = {\n",
        "      'GaussianNB':GaussianNB,\n",
        "      'MultinomialNB':MultinomialNB\n",
        "\n",
        "  }\n",
        "  model = models[model_name]()  \n",
        "  return model\n",
        "\n",
        "def get_random_forest_model(n_estimators=100):\n",
        "  model = RandomForestClassifier(n_estimators=n_estimators)\n",
        "  return model\n",
        "\n",
        "def get_knn_model(n_neighbors=5,metric='minkowski',p=2): \n",
        "    model = KNeighborsClassifier(n_neighbors = n_neighbors, metric =metric, p = p)\n",
        "    return model\n",
        "\n",
        "def get_svm_model(poly_degree=3,poly_c=1):\n",
        "  model = svm.SVC(kernel='poly', degree=poly_degree, C=poly_c)\n",
        "  return model\n",
        "\n",
        "def get_predict_from_model(model,x_test):\n",
        "    y_pred = model.predict(x_test)\n",
        "    return y_pred\n",
        "\n",
        "def get_accuracy_score(model,x_test,y_test,model_name):\n",
        "    y_pred = get_predict_from_model(model,x_test)\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    # poly_f1 = f1_score(y_test, poly_pred, average='weighted')\n",
        "    # print('Accuracy (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
        "    # cm = confusion_matrix(y_test, y_pred)\n",
        "    print('Model: {model_name}  Accuracy score: {acc_score}'.format(model_name=model_name,acc_score=acc_score))\n",
        "    return y_pred\n",
        "\n",
        "def run_model(model,x_train, y_train,x_test,y_test,model_name):\n",
        "  model.fit(x_train, y_train)\n",
        "  return get_accuracy_score(model,x_test,y_test,model_name)\n",
        "\n",
        "\n",
        "def run_model_with_cv(model_name,model, x, y,n_splits=5):\n",
        "    kf=KFold(n_splits=n_splits)\n",
        "    scoring = {'accuracy':'accuracy','f1':'f1_weighted','precision':'precision_weighted',\n",
        "               'recall':'recall_weighted'}\n",
        "    results = cross_validate(estimator=model,\n",
        "                              X=x,\n",
        "                              y=y,\n",
        "                              cv=kf,\n",
        "                              scoring=scoring,\n",
        "                              return_train_score=True)\n",
        "    data ={\n",
        "            # \"Training Accuracy scores\": results['train_accuracy'],\n",
        "            \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
        "            # \"Training Precision scores\": results['train_precision'],\n",
        "            \"Mean Training Precision\": results['train_precision'].mean(),\n",
        "            # \"Training Recall scores\": results['train_recall'],\n",
        "            \"Mean Training Recall\": results['train_recall'].mean(),\n",
        "            # \"Training F1 scores\": results['train_f1'],\n",
        "            \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
        "            # \"Validation Accuracy scores\": results['test_accuracy'],\n",
        "            \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
        "            # \"Validation Precision scores\": results['test_precision'],\n",
        "            \"Mean Validation Precision\": results['test_precision'].mean(),\n",
        "            # \"Validation Recall scores\": results['test_recall'],\n",
        "            \"Mean Validation Recall\": results['test_recall'].mean(),\n",
        "            # \"Validation F1 scores\": results['test_f1'],\n",
        "            \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
        "            }\n",
        "    print(model_name,data)\n",
        "    return data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(label_encoder,results):\n",
        "  labels_inversed = label_encoder.inverse_transform(results)\n",
        "  return labels_inversed\n",
        "\n",
        "def show_predictions(labels,x_test,sample=5):\n",
        "  total = len(labels[0:sample])\n",
        "  breaker = 4\n",
        "  _, ax = plt.subplots((total//4)+1,4,figsize=(15, 8))\n",
        "  results = []\n",
        "  for idx,img_ar in enumerate(x_test[0:sample]):\n",
        "      results.append(labels[idx])\n",
        "      img = np.round(img_ar * 255).astype(int).reshape(128,128)\n",
        "      title = f\"Prediction: {labels[idx]}\"\n",
        "      ax[idx // breaker, idx % breaker].imshow(img, cmap=\"gray\")\n",
        "      ax[idx // breaker, idx % breaker].set_title(title)\n",
        "      ax[idx // breaker, idx % breaker].axis(\"off\")\n",
        "  for idx in range((total//4+1) *4):\n",
        "     ax[idx // breaker, idx % breaker].axis(\"off\")\n",
        "  plt.show()\n",
        "  return results"
      ],
      "metadata": {
        "id": "p-Bw3pkar8tD"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def thresholding(image):\n",
        "    img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "    # plt.imshow(thresh, cmap='gray')\n",
        "    return thresh\n",
        "\n",
        "def get_bounding_box_from_image(file_name):\n",
        "  img = read_image(file_name,color=True)\n",
        "  # plt.imshow(img);\n",
        "  thresh_img = thresholding(img);\n",
        "  # #dilation\n",
        "  kernel = np.ones((3,85), np.uint8)\n",
        "  dilated = cv2.dilate(thresh_img, kernel, iterations = 1)\n",
        "  # plt.imshow(dilated, cmap='gray');\n",
        "  (contours, heirarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "  sorted_contours_lines = sorted(contours, key = lambda ctr : cv2.boundingRect(ctr)[1]) # (x, y, w, h)\n",
        "  #dilation\n",
        "  kernel = np.ones((3,15), np.uint8)\n",
        "  dilated2 = cv2.dilate(thresh_img, kernel, iterations = 1)\n",
        "  # plt.imshow(dilated2, cmap='gray');\n",
        "  img3 = img.copy()\n",
        "  bounding_boxes = []\n",
        "\n",
        "  for line in sorted_contours_lines:\n",
        "      \n",
        "      # roi of each line\n",
        "      x, y, w, h = cv2.boundingRect(line)\n",
        "      roi_line = dilated2[y:y+h, x:x+w]\n",
        "      \n",
        "      # draw contours on each word\n",
        "      (cnt, heirarchy) = cv2.findContours(roi_line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "      sorted_contour_words = sorted(cnt, key=lambda cntr : cv2.boundingRect(cntr)[0])\n",
        "      \n",
        "      for word in sorted_contour_words:\n",
        "          \n",
        "          if cv2.contourArea(word) < 400:\n",
        "              continue\n",
        "          \n",
        "          x2, y2, w2, h2 = cv2.boundingRect(word)\n",
        "          bounding_boxes.append([x+x2, y+y2, x+x2+w2, y+y2+h2])\n",
        "          cv2.rectangle(img3, (x+x2, y+y2), (x+x2+w2, y+y2+h2), (0, 255, 0),2)\n",
        "  show_image(img3)\n",
        "  return bounding_boxes\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GCpN2Dgv958d"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_from_image(image_path):\n",
        "  bounding_boxes = get_bounding_box_from_image(image_path)\n",
        "  word_images = []\n",
        "  img = read_image(image_path)\n",
        "  for bounding_box in bounding_boxes:\n",
        "    x, y, w, h = bounding_box\n",
        "    cropped_img = img[y:h,x:w].copy()\n",
        "    word_image = process_image(cropped_img)\n",
        "    word_images.append(word_image)\n",
        "  return word_images "
      ],
      "metadata": {
        "id": "Mb-8FABnAzx6"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_audio_using_gtts(text):\n",
        "  tts = gTTS(text,lang='en',slow=True)\n",
        "  file_name='1.wav' \n",
        "  tts.save(file_name)\n",
        "  return file_name\n",
        "\n",
        "def convert_to_audio(words,engine_type='gtts'):\n",
        "  if engine_type=='gtts':\n",
        "      return convert_to_audio_using_gtts(\" \".join(words))\n",
        "  "
      ],
      "metadata": {
        "id": "B2gUFLEAj-TF"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_count(label_encoder,y_train,y_test):\n",
        "  words = []\n",
        "  for i in get_predictions(label_encoder,y_train):\n",
        "    words.append(i)\n",
        "  for i in get_predictions(label_encoder,y_test):\n",
        "    words.append(i)\n",
        "  Counter(words)"
      ],
      "metadata": {
        "id": "bdH1JaAVcWT4"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize(model,image_path,show_sample=10):\n",
        "  show_image(cv2.imread(image_path))\n",
        "  words = np.array(get_words_from_image(image_path))/NORMALIZE_SCALE\n",
        "  preds = get_predict_from_model(model,words)\n",
        "  predicted_labels = get_predictions(label_encoder,preds)\n",
        "  sound_file = convert_to_audio(predicted_labels)\n",
        "  show_predictions(predictions,words,sample=show_sample)\n",
        "  return sound_file, predicted_labels"
      ],
      "metadata": {
        "id": "mwwAMzn1LheF"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 100\n",
        "MAX_IMAGES_PER_WORD = 200\n",
        "TEST_DATASET_SIZE = 0.05\n",
        "NORMALIZE_SCALE = 255.0\n",
        "IMAGE_SIZE = (128,128)\n",
        "TRAIN_WORDS = {'the', 'he', 'for', 'stop', 'on', 'Foot', 'Labour', 'at', 'Griffiths', 'and', 'of', 'by', 'any', '.', 'subject', 'Peers', 'tomorrow', 'nominating', 'has', 'Mr.', 'backed', 'MOVE', 'life', 'be', 'is', 'resolution', 'Ps', 'meeting', 'a', 'from', 'Michael', 'Gaitskell', 'more', 'put', 'Exchange', 'Manchester', 'to', 'down', 'Will', ',', 'made', 'P', 'A'}"
      ],
      "metadata": {
        "id": "ts8T8nf5Euh5"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_path_for_images = \"/words\"\n",
        "file_path = \"/words_label/words.txt\"\n"
      ],
      "metadata": {
        "id": "f-OIOOIHA566"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_for_labels = get_input_for_labels_based_on_training_words(file_path,TRAIN_WORDS,MAX_IMAGES_PER_WORD)\n",
        "input_data = get_images_and_labels(base_path_for_images, input_for_labels,\n",
        "                                   IMAGE_SIZE)\n",
        "\n",
        "random.shuffle(input_data)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "features,labels = get_features_and_labels(input_data,label_encoder)\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(features,labels,\n",
        "                                                 test_size=TEST_DATASET_SIZE)\n",
        "\n",
        "x_train,x_test = x_train/NORMALIZE_SCALE,x_test/NORMALIZE_SCALE\n",
        "\n",
        "features = features/NORMALIZE_SCALE\n",
        "print(len(x_train),len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I76gqvxmRrD",
        "outputId": "30012c4c-aa35-4c96-863c-7c28451deb77"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4063 214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_word_count(label_encoder,y_train,y_test)"
      ],
      "metadata": {
        "id": "bgWpqz9YprEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = None\n",
        "model_names = [\n",
        "      'GaussianNB',\n",
        "      'MultinomialNB'\n",
        "]\n",
        "for model_name in model_names:\n",
        "  nb_model = get_gaussian_model(model_name)\n",
        "  results = run_model(nb_model,x_train, y_train,x_test,y_test,model_name)\n",
        "  run_model_with_cv(model_name,nb_model,x_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QR-UQRDVZ6FA",
        "outputId": "4c5d070c-755f-4369-ce7d-d1911ceea049"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: GaussianNB  Accuracy score: 0.5186915887850467\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GaussianNB {'Training Accuracy scores': array([0.64830769, 0.64061538, 0.64615385, 0.63795755, 0.65579822]), 'Mean Training Accuracy': 64.57665381066181, 'Training Precision scores': array([0.68666453, 0.68468765, 0.69696946, 0.68043367, 0.69480002]), 'Mean Training Precision': 0.6887110653171352, 'Training Recall scores': array([0.64830769, 0.64061538, 0.64615385, 0.63795755, 0.65579822]), 'Mean Training Recall': 0.6457665381066181, 'Training F1 scores': array([0.64310312, 0.64248345, 0.64353651, 0.63531453, 0.65401131]), 'Mean Training F1 Score': 0.6436897824646938, 'Validation Accuracy scores': array([0.56949569, 0.57195572, 0.53628536, 0.53078818, 0.57389163]), 'Mean Validation Accuracy': 55.64833160646877, 'Validation Precision scores': array([0.60962479, 0.61324873, 0.58678749, 0.5715949 , 0.62076268]), 'Mean Validation Precision': 0.6004037163398517, 'Validation Recall scores': array([0.56949569, 0.57195572, 0.53628536, 0.53078818, 0.57389163]), 'Mean Validation Recall': 0.5564833160646877, 'Validation F1 scores': array([0.56354909, 0.57089035, 0.53801945, 0.52197004, 0.56598047]), 'Mean Validation F1 Score': 0.5520818817462849}\n",
            "Model: MultinomialNB  Accuracy score: 0.5794392523364486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB {'Training Accuracy scores': array([0.67046154, 0.66492308, 0.67353846, 0.67886804, 0.66871732]), 'Mean Training Accuracy': 67.13016870548707, 'Training Precision scores': array([0.6974454 , 0.69685096, 0.70115241, 0.704975  , 0.69665565]), 'Mean Training Precision': 0.6994158867707749, 'Training Recall scores': array([0.67046154, 0.66492308, 0.67353846, 0.67886804, 0.66871732]), 'Mean Training Recall': 0.6713016870548707, 'Training F1 scores': array([0.67501011, 0.67112855, 0.67797704, 0.68316913, 0.67329304]), 'Mean Training F1 Score': 0.6761155736356493, 'Validation Accuracy scores': array([0.63714637, 0.63099631, 0.56703567, 0.60837438, 0.60714286]), 'Mean Validation Accuracy': 61.01391186325657, 'Validation Precision scores': array([0.67089297, 0.66607368, 0.62970445, 0.63741019, 0.65218723]), 'Mean Validation Precision': 0.651253702881182, 'Validation Recall scores': array([0.63714637, 0.63099631, 0.56703567, 0.60837438, 0.60714286]), 'Mean Validation Recall': 0.6101391186325656, 'Validation F1 scores': array([0.644078  , 0.63373833, 0.58203706, 0.61205714, 0.61886814]), 'Mean Validation F1 Score': 0.6181557335949146}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'KNN'\n",
        "knn_model = get_knn_model()\n",
        "run_model(knn_model,x_train, y_train,x_test,y_test,model_name)\n",
        "run_model_with_cv(model_name,knn_model,x_train, y_train)"
      ],
      "metadata": {
        "id": "-DmkvMZnb0bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65880fb-a9b8-414e-a345-b9cfa9ecf247"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: KNN  Accuracy score: 0.6401869158878505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN {'Training Accuracy scores': array([0.77846154, 0.77384615, 0.79076923, 0.80375269, 0.78037527]), 'Mean Training Accuracy': 78.54409767408845, 'Training Precision scores': array([0.8213368 , 0.81078295, 0.82456927, 0.83006074, 0.82300065]), 'Mean Training Precision': 0.8219500828072525, 'Training Recall scores': array([0.77846154, 0.77384615, 0.79076923, 0.80375269, 0.78037527]), 'Mean Training Recall': 0.7854409767408845, 'Training F1 scores': array([0.77563579, 0.76787953, 0.78732757, 0.80007051, 0.77973992]), 'Mean Training F1 Score': 0.7821306668159582, 'Validation Accuracy scores': array([0.68142681, 0.69126691, 0.64575646, 0.6637931 , 0.65640394]), 'Mean Validation Accuracy': 66.77294457673642, 'Validation Precision scores': array([0.73529071, 0.74102244, 0.70200333, 0.71419803, 0.70478773]), 'Mean Validation Precision': 0.7194604480250186, 'Validation Recall scores': array([0.68142681, 0.69126691, 0.64575646, 0.6637931 , 0.65640394]), 'Mean Validation Recall': 0.6677294457673641, 'Validation F1 scores': array([0.66805052, 0.68732575, 0.63318848, 0.65069416, 0.64525713]), 'Mean Validation F1 Score': 0.6569032070564178}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Training Accuracy scores': array([0.77846154, 0.77384615, 0.79076923, 0.80375269, 0.78037527]),\n",
              " 'Mean Training Accuracy': 78.54409767408845,\n",
              " 'Training Precision scores': array([0.8213368 , 0.81078295, 0.82456927, 0.83006074, 0.82300065]),\n",
              " 'Mean Training Precision': 0.8219500828072525,\n",
              " 'Training Recall scores': array([0.77846154, 0.77384615, 0.79076923, 0.80375269, 0.78037527]),\n",
              " 'Mean Training Recall': 0.7854409767408845,\n",
              " 'Training F1 scores': array([0.77563579, 0.76787953, 0.78732757, 0.80007051, 0.77973992]),\n",
              " 'Mean Training F1 Score': 0.7821306668159582,\n",
              " 'Validation Accuracy scores': array([0.68142681, 0.69126691, 0.64575646, 0.6637931 , 0.65640394]),\n",
              " 'Mean Validation Accuracy': 66.77294457673642,\n",
              " 'Validation Precision scores': array([0.73529071, 0.74102244, 0.70200333, 0.71419803, 0.70478773]),\n",
              " 'Mean Validation Precision': 0.7194604480250186,\n",
              " 'Validation Recall scores': array([0.68142681, 0.69126691, 0.64575646, 0.6637931 , 0.65640394]),\n",
              " 'Mean Validation Recall': 0.6677294457673641,\n",
              " 'Validation F1 scores': array([0.66805052, 0.68732575, 0.63318848, 0.65069416, 0.64525713]),\n",
              " 'Mean Validation F1 Score': 0.6569032070564178}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'Random Forest'\n",
        "rf_model = get_random_forest_model()\n",
        "run_model(rf_model,x_train, y_train,x_test,y_test,model_name)\n",
        "run_model_with_cv(model_name,rf_model,x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUoQ378YBkK-",
        "outputId": "b9b531c7-9c62-43a7-dece-d333de4fd17f"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Random Forest  Accuracy score: 0.7429906542056075\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest {'Training Accuracy scores': array([0.99969231, 1.        , 0.99969231, 0.9996924 , 1.        ]), 'Mean Training Accuracy': 99.98154035444715, 'Training Precision scores': array([0.9996942 , 1.        , 0.99969433, 0.99969443, 1.        ]), 'Mean Training Precision': 0.9998165906731111, 'Training Recall scores': array([0.99969231, 1.        , 0.99969231, 0.9996924 , 1.        ]), 'Mean Training Recall': 0.9998154035444715, 'Training F1 scores': array([0.99969228, 1.        , 0.99969231, 0.99969234, 1.        ]), 'Mean Training F1 Score': 0.9998153864854362, 'Validation Accuracy scores': array([0.73431734, 0.7601476 , 0.72570726, 0.72413793, 0.73275862]), 'Mean Validation Accuracy': 73.5413750689231, 'Validation Precision scores': array([0.73245489, 0.75116997, 0.72358047, 0.73351149, 0.72553002]), 'Mean Validation Precision': 0.7332493691297236, 'Validation Recall scores': array([0.73431734, 0.7601476 , 0.72570726, 0.72413793, 0.73275862]), 'Mean Validation Recall': 0.735413750689231, 'Validation F1 scores': array([0.71671366, 0.74300862, 0.71136931, 0.70531859, 0.71087456]), 'Mean Validation F1 Score': 0.7174569473936113}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Training Accuracy scores': array([0.99969231, 1.        , 0.99969231, 0.9996924 , 1.        ]),\n",
              " 'Mean Training Accuracy': 99.98154035444715,\n",
              " 'Training Precision scores': array([0.9996942 , 1.        , 0.99969433, 0.99969443, 1.        ]),\n",
              " 'Mean Training Precision': 0.9998165906731111,\n",
              " 'Training Recall scores': array([0.99969231, 1.        , 0.99969231, 0.9996924 , 1.        ]),\n",
              " 'Mean Training Recall': 0.9998154035444715,\n",
              " 'Training F1 scores': array([0.99969228, 1.        , 0.99969231, 0.99969234, 1.        ]),\n",
              " 'Mean Training F1 Score': 0.9998153864854362,\n",
              " 'Validation Accuracy scores': array([0.73431734, 0.7601476 , 0.72570726, 0.72413793, 0.73275862]),\n",
              " 'Mean Validation Accuracy': 73.5413750689231,\n",
              " 'Validation Precision scores': array([0.73245489, 0.75116997, 0.72358047, 0.73351149, 0.72553002]),\n",
              " 'Mean Validation Precision': 0.7332493691297236,\n",
              " 'Validation Recall scores': array([0.73431734, 0.7601476 , 0.72570726, 0.72413793, 0.73275862]),\n",
              " 'Mean Validation Recall': 0.735413750689231,\n",
              " 'Validation F1 scores': array([0.71671366, 0.74300862, 0.71136931, 0.70531859, 0.71087456]),\n",
              " 'Mean Validation F1 Score': 0.7174569473936113}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'SVM Poly'\n",
        "svm_poly = get_svm_model()\n",
        "run_model(svm_poly,x_train, y_train,x_test,y_test,model_name)\n",
        "run_model_with_cv(model_name,svm_poly,x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qppDt3UfDcYc",
        "outputId": "fe76d525-b408-4785-abc0-20c5bb525a92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: SVM Poly  Accuracy score: 0.7663551401869159\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8MrxDGuuNf3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/samples/sample1.png'\n",
        "final_model = svm_poly\n",
        "sound_file,predictions = recognize(final_model,image_path,show_sample=10)\n",
        "print(\" \".join(predictions))\n",
        "Audio(sound_file, autoplay=True)\n"
      ],
      "metadata": {
        "id": "Uy7fNMiIAqAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ug3rdJ_XzUNb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}